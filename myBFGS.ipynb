{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Toms566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myBFGS (generic function with 3 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myBFGS(obj, x0, maxIts=500, optTol=1e-5)\n",
    "    # Minimize a function f using BFGS method \n",
    "    \n",
    "    # INPUT\n",
    "    # obj: a function that evaluates the objective value, gradient and Hessian at point x, i.e. (f,g,H)=obj(x)\n",
    "    # x0: starting point\n",
    "    # maxIts (optional): maximum number of iterations.\n",
    "    # optTol (optional): optimality tolerance based on: ||grad(x)|| <= optTol*||grad(x0)||\n",
    "    \n",
    "    # OUTPUT\n",
    "    # xmin: Minimum point\n",
    "    # fmin: Minimum \n",
    "    # iter: Number of iterations\n",
    "    # fgrdnorm: 2-norm of gradient of test problem at minimum point\n",
    "    \n",
    "    # Using of Newton mathod, backtracking line search with Wolfe condition\n",
    "    \n",
    "    # initialize\n",
    "    x_old = obj.x0;; # standard starting point\n",
    "    x_new = x_old;\n",
    "    \n",
    "    alpha0 = 0.2; # para for backtracking line serch\n",
    "    beta0 = 0.5;\n",
    "    \n",
    "    B_inverse = eye(obj.n);\n",
    "    \n",
    "    iter = 0;\n",
    "    ratio = 1;\n",
    "    \n",
    "    # loop with BFGS Mehtod\n",
    "    iter = 0; # number of iteration\n",
    "    ratio = 1;\n",
    "    \n",
    "    while ratio > optTol && iter < maxIts\n",
    "        p_k = - B_inverse * obj.grd(x_old);\n",
    "        # backtracking line search\n",
    "        t = 1.0;\n",
    "    \n",
    "        #difference of L/R Hand Side of Wolfe condition \n",
    "        diff1 = 1.0; # just initialize loop for backtracking\n",
    "        #diff2 = 1.0;\n",
    "        #c1=1/4;c2=1/2;\n",
    "    \n",
    "        \n",
    "        while diff1[1] > 0 #&& diff2[1] > 0\n",
    "            f_old = obj.obj(x_old); # f_old := f(x)\n",
    "            x_new = x_old + t * p_k;\n",
    "            f_new = obj.obj(x_new); # f_new := f(x + \\delta x)\n",
    "        \n",
    "            #wolfe condition\n",
    "            diff1 = f_new - f_old - alpha0 * t * obj.grd(x_old)' * p_k;\n",
    "            #diff2 = c2 * obj.grd(x_old)' * p_k - obj.grd(x_new)' * p_k;\n",
    "\n",
    "            t = beta0 * t;\n",
    "        end\n",
    "        \n",
    "        # update x_new (this step contains in the loop of line search)\n",
    "        x_new = x_old + t * p_k\n",
    "\n",
    "        s = t * p_k\n",
    "        y = obj.grd(x_new) - obj.grd(x_old)\n",
    "\n",
    "        StY = ( s' * y )[1]  # StY = s ^ T _ k * y _ k\n",
    "\n",
    "        #update approximation of Hessian\n",
    "        B_inverse =  B_inverse + (StY + y' * B_inverse * y)[1] / ( StY[1] ^ 2 ) * (s * s') - ( B_inverse * y * s' + s * y' * B_inverse) / StY[1];\n",
    "    \n",
    "        x_old = x_new;\n",
    "        ratio = norm(obj.grd(x_old)) / norm(obj.grd(x0));\n",
    "        \n",
    "        iter = iter + 1;\n",
    "        if iter >= maxIts\n",
    "            println(\"REACH MAXIMUM ITERATION NUMBER!\");\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    xmin = x_old;\n",
    "    fmin = obj.obj(x_old);\n",
    "    fgrdnorm = norm(obj.grd(x_old));\n",
    "    return (xmin,fmin,iter,fgrdnorm);\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Problem 1\n",
      "Minimum Point\n",
      "[1.0000000000000062,7.640104499804546e-14,1.2408572090724623e-13]\n",
      "Minimum: \n",
      "1.9882535825875306e-26\n",
      "Number of Iterations\n",
      "70\n",
      "Final gradient norm\n",
      "1.6525388598768545e-12\n",
      "\n",
      "\n",
      "For Problem 2\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN,NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "85\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 3\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "35\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 4\n",
      "Minimum Point\n",
      "[1.0981593296998956e-5,9.106146739865876]\n",
      "Minimum: \n",
      "1.2140083212010259e-34\n",
      "Number of Iterations\n",
      "215\n",
      "Final gradient norm\n",
      "2.2036167297925165e-17\n",
      "\n",
      "\n",
      "For Problem 5\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "5\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 6\n",
      "Minimum Point\n",
      "[0.9999999999882824,0.9999999999755976,0.9999999999593365,0.9999999999661258,0.9999999999207151,0.999999999921091,0.9999999998932008,0.9999999999103727,0.9999999998720647,0.9999999998683564,0.9999999998516935,0.9999999998459452,0.9999999998399551,0.9999999998047482,0.999999999789381,0.9999999998769952,0.9999999997937521,0.999999999792432,0.9999999997429272,0.9999999997330321,0.9999999997185919,0.9999999996773545,0.9999999997014569,0.9999999996905999,0.9999999996675534,0.9999999996990819,0.9999999996339265,0.9999999996396831,0.9999999996137372,0.9999999995407141,0.9999999995926618,0.999999999675142,0.9999999996155213,0.9999999995634334,0.9999999995231366,0.9999999995529059,0.9999999995486439,0.9999999994481082,0.9999999995059294,0.9999999994477052]\n",
      "Minimum: \n",
      "8.223974975422631e-14\n",
      "Number of Iterations\n",
      "64\n",
      "Final gradient norm\n",
      "8.534329579072401e-5\n",
      "\n",
      "\n",
      "For Problem 7\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "133\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 8\n",
      "Minimum Point\n",
      "[0.06456890834983021,0.06456488279487407,0.0645693347074351,0.06456126156132104,0.06454641430467051,0.06457937612066868,0.06455913281558058,0.06455488313558327,0.06456209045207358,0.06455164369583002,0.06458742781110277,0.06455815498540608,0.06453452576417416,0.06456291504546187,0.06455970302755248,0.06455074214758803,0.06457026519693919,0.06455619686471431,0.06457205216581383,0.06456668330866805,0.06456337007950048,0.06456283949586022,0.06457481133175681,0.06455440421695538,0.06453146994929039,0.06456665358980637,0.06454952210505698,0.06457610603120298,0.06457509892076481,0.06456257177085839,0.06455620037033155,0.06449917504027115,0.06455400837551692,0.06453538287410984,0.0645776584110859,0.06457527453554866,0.06458408392093865,0.06453829140557081,0.06455379112730765,0.06458880010280119,0.06449629755443756,0.06452997729800229,0.06454072071517816,0.06455212665262504,0.06453871349317537,0.06450262465798111,0.0645566681397193,0.06453480038929636,0.06458892977371607,0.06460371931085149,0.06451852510873933,0.06464852508221361,0.06451974615082946,0.06457487955280977,0.06455834213569953,0.06455675376331987,0.06458697777990999,0.06454838921720912,0.064588153147317,0.06458307939304421]\n",
      "Minimum: \n",
      "0.0005250350892628017\n",
      "Number of Iterations\n",
      "327\n",
      "Final gradient norm\n",
      "7.02699376585519e-8\n",
      "\n",
      "\n",
      "For Problem 9\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "623\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 10\n",
      "Minimum Point\n",
      "[1.0e6,2.0000000000000008e-6]\n",
      "Minimum: \n",
      "7.888609052217293e-31\n",
      "Number of Iterations\n",
      "66\n",
      "Final gradient norm\n",
      "1.7763568394019445e-9\n",
      "\n",
      "\n",
      "For Problem 11\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "45\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 12\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "15\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 13\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "98\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "For Problem 14\n",
      "Minimum Point\n",
      "[0.9999999999998646,0.9999999999997284,1.0000000000001072,1.0000000000002147,0.9999999999997268,0.9999999999994525,1.0000000000000822,1.0000000000001645,0.9999999999996351,0.9999999999992686,0.9999999999998509,0.9999999999997011,1.0000000000000593,1.000000000000119,0.9999999999997894,0.9999999999995777,0.9999999999997986,0.9999999999995965,0.999999999999904,0.9999999999998074,1.0000000000005094,1.0000000000010207,0.9999999999999918,0.9999999999999833,1.0000000000005456,1.0000000000010931,0.9999999999998362,0.9999999999996717,0.9999999999999548,0.9999999999999092,1.000000000000258,1.000000000000517,1.0000000000001499,1.0000000000003004,0.9999999999997405,0.9999999999994802,0.999999999999972,0.9999999999999439,1.0000000000001414,1.000000000000283]\n",
      "Minimum: \n",
      "1.1292272194264549e-24\n",
      "Number of Iterations\n",
      "436\n",
      "Final gradient norm\n",
      "1.0086055938142995e-12\n",
      "\n",
      "\n",
      "For Problem 15\n",
      "Minimum Point\n",
      "[-8.176335228419694e-6,8.176335226152172e-7,8.478087595580618e-6,8.478087588980764e-6,1.551609806364065e-5,-1.5516098066878048e-6,-1.36318141497476e-6,-1.363181412513838e-6,3.774924237205172e-5,-3.774924236078845e-6,1.5043162314454097e-5,1.5043162319824731e-5,1.1727184101224394e-5,-1.1727184099317326e-6,-1.2500808031227854e-5,-1.2500808044681656e-5,-2.03753817206083e-5,2.0375381724554894e-6,-9.161003875832478e-6,-9.161003865422597e-6,-1.3222592259465495e-5,1.3222592254855072e-6,-1.8109840827368735e-5,-1.8109840844367114e-5,-4.630499518521353e-5,4.630499516733138e-6,-2.1991562319370426e-5,-2.1991562358643376e-5,4.132226879349709e-6,-4.132226870174604e-7,2.1390671702501987e-5,2.1390671735510308e-5,8.392318320461677e-6,-8.392318317301966e-7,1.3662113942165804e-5,1.3662113953527489e-5,-5.001604891650117e-6,5.00160489304108e-7,-1.2736184812443838e-5,-1.2736184817744088e-5,1.9584985089804234e-5,-1.958498508666057e-6,1.1919328069809971e-5,1.1919328067282876e-5,-3.2183552018152103e-6,3.2183552060951033e-7,4.7204730082175436e-7,4.7204730887757746e-7,1.8269822138222915e-6,-1.8269822100498613e-7,3.3078438264507103e-7,3.307843867826531e-7,2.1895983055354584e-5,-2.189598305307047e-6,8.988444240711455e-6,8.988444244196262e-6,2.295973881036672e-5,-2.2959738807128005e-6,8.709186497875185e-6,8.709186497919251e-6]\n",
      "Minimum: \n",
      "2.7773104823056756e-17\n",
      "Number of Iterations\n",
      "901\n",
      "Final gradient norm\n",
      "1.7046071934596719e-12\n",
      "\n",
      "\n",
      "For Problem 16\n",
      "Minimum Point\n",
      "[2.9999999999999925,0.49999999999999856]\n",
      "Minimum: \n",
      "1.1635698352009924e-29\n",
      "Number of Iterations\n",
      "59\n",
      "Final gradient norm\n",
      "2.0545126284631496e-14\n",
      "\n",
      "\n",
      "For Problem 17\n",
      "Minimum Point\n",
      "[0.9999999999999759,0.9999999999999567,1.0000000000003029,1.0000000000005864]\n",
      "Minimum: \n",
      "3.1177423731061537e-24\n",
      "Number of Iterations\n",
      "139\n",
      "Final gradient norm\n",
      "1.5962072933797967e-11\n",
      "\n",
      "\n",
      "For Problem 18\n",
      "Minimum Point\n",
      "[NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN,NaN]\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "289\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# solve 18 problem with BFGS method\n",
    "for i = 1:18\n",
    "    obj = Problem(i);\n",
    "    x0 = obj.x0;\n",
    "    maxIts=10000; \n",
    "    optTol=1e-15;\n",
    "    (xmin,fmin,it,fgrdnorm) = myBFGS(obj,x0,maxIts,optTol);\n",
    "    # Print outputs\n",
    "    println(\"For Problem \",i)\n",
    "    #println(\"Minimum Point\")\n",
    "    #println(xmin)\n",
    "    println(\"Minimum: \")\n",
    "    println(fmin)\n",
    "    println(\"Number of Iterations\")\n",
    "    println(it)\n",
    "    println(\"Final gradient norm\")\n",
    "    println(fgrdnorm)\n",
    "    println(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimum Point\n",
      "Minimum: \n",
      "3.00094961099333e-8\n",
      "Number of Iterations\n",
      "4\n",
      "Final gradient norm\n",
      "0.0005143218956198588\n",
      "\n",
      "\n",
      "Minimum: \n",
      "NaN\n",
      "Number of Iterations\n",
      "5\n",
      "Final gradient norm\n",
      "NaN\n",
      "\n",
      "\n",
      "Minimum: \n",
      "649005.3281656587\n",
      "Number of Iterations\n",
      "5\n",
      "Final gradient norm\n",
      "203260.43128450238\n",
      "\n",
      "\n",
      "Minimum: \n",
      "6.597962343410366\n",
      "Number of Iterations\n",
      "3\n",
      "Final gradient norm\n",
      "3.874172238265467\n",
      "\n",
      "\n",
      "Minimum: \n",
      "7.332604438391326e-5\n",
      "Number of Iterations\n",
      "9\n",
      "Final gradient norm\n",
      "0.004194491318392039\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i = [3,5,11,12,13] \n",
    "    obj = Problem(i);\n",
    "    x0 = obj.x0;\n",
    "    maxIts=10000; \n",
    "    optTol=1e-1;\n",
    "    (xmin,fmin,it,fgrdnorm) = myBFGS(obj,x0,maxIts,optTol);\n",
    "    \n",
    "    println(\"Minimum: \")\n",
    "    println(fmin)\n",
    "    println(\"Number of Iterations\")\n",
    "    println(it)\n",
    "    println(\"Final gradient norm\")\n",
    "    println(fgrdnorm)\n",
    "    println(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
